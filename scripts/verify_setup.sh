#!/bin/bash

# Script de verificaci√≥n post-instalaci√≥n para DuckLake
# Verifica que todas las configuraciones est√©n correctas

set -e

echo "=================================================================="
echo "  üîç VERIFICACI√ìN POST-INSTALACI√ìN - DuckLake con Airflow"
echo "=================================================================="
echo ""

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Funci√≥n para imprimir estado
print_status() {
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}‚úÖ $2${NC}"
    else
        echo -e "${RED}‚ùå $2${NC}"
    fi
}

# Funci√≥n para imprimir warning
print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

# Funci√≥n para imprimir info
print_info() {
    echo "‚ÑπÔ∏è  $1"
}

ERRORS=0

# 1. Verificar archivos de configuraci√≥n
echo "1Ô∏è‚É£  Verificando archivos de configuraci√≥n..."
echo ""

if [ -f ".env" ]; then
    print_status 0 ".env encontrado"
else
    print_status 1 ".env NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

if [ -f "docker-compose.yml" ]; then
    print_status 0 "docker-compose.yml encontrado"
else
    print_status 1 "docker-compose.yml NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

if [ -f "airflow/Dockerfile" ]; then
    print_status 0 "airflow/Dockerfile encontrado"
    
    # Verificar que contenga las extensiones de DuckDB
    if grep -q "INSTALL ducklake" "airflow/Dockerfile"; then
        print_status 0 "  ‚îî‚îÄ Extensiones DuckDB configuradas en Dockerfile"
    else
        print_status 1 "  ‚îî‚îÄ Extensiones DuckDB NO configuradas en Dockerfile"
        print_warning "     A√±ade: RUN python -c \"import duckdb; con = duckdb.connect(); con.execute('INSTALL ducklake; INSTALL postgres; INSTALL httpfs;'); con.close()\""
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "airflow/Dockerfile NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

if [ -f "airflow/requirements.txt" ]; then
    print_status 0 "airflow/requirements.txt encontrado"
    
    # Verificar providers
    if grep -q "apache-airflow-providers-postgres" "airflow/requirements.txt"; then
        print_status 0 "  ‚îî‚îÄ Provider PostgreSQL configurado"
    else
        print_status 1 "  ‚îî‚îÄ Provider PostgreSQL NO configurado"
        ERRORS=$((ERRORS + 1))
    fi
    
    if grep -q "apache-airflow-providers-amazon" "airflow/requirements.txt"; then
        print_status 0 "  ‚îî‚îÄ Provider AWS/S3 configurado"
    else
        print_status 1 "  ‚îî‚îÄ Provider AWS/S3 NO configurado"
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "airflow/requirements.txt NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

if [ -f "airflow/airflow_settings.yaml" ]; then
    print_status 0 "airflow/airflow_settings.yaml encontrado"
    
    # Verificar conexiones
    if grep -q "postgres_datos_externos" "airflow/airflow_settings.yaml"; then
        print_status 0 "  ‚îî‚îÄ Conexi√≥n PostgreSQL configurada"
    else
        print_status 1 "  ‚îî‚îÄ Conexi√≥n PostgreSQL NO configurada"
        ERRORS=$((ERRORS + 1))
    fi
    
    if grep -q "rustfs_s3_conn" "airflow/airflow_settings.yaml"; then
        print_status 0 "  ‚îî‚îÄ Conexi√≥n RustFS configurada"
    else
        print_status 1 "  ‚îî‚îÄ Conexi√≥n RustFS NO configurada"
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "airflow/airflow_settings.yaml NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

if [ -f "airflow/dags/utils.py" ]; then
    print_status 0 "airflow/dags/utils.py encontrado"
    
    # Verificar funci√≥n
    if grep -q "connect_datalake_from_airflow" "airflow/dags/utils.py"; then
        print_status 0 "  ‚îî‚îÄ Funci√≥n connect_datalake_from_airflow() definida"
    else
        print_status 1 "  ‚îî‚îÄ Funci√≥n connect_datalake_from_airflow() NO definida"
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "airflow/dags/utils.py NO encontrado"
    ERRORS=$((ERRORS + 1))
fi

echo ""

# 2. Verificar contenedores Docker
echo "2Ô∏è‚É£  Verificando contenedores Docker..."
echo ""

if docker ps | grep -q "postgresql"; then
    print_status 0 "PostgreSQL est√° corriendo"
    
    # Verificar conectividad
    if docker exec postgresql pg_isready -U admin > /dev/null 2>&1; then
        print_status 0 "  ‚îî‚îÄ PostgreSQL acepta conexiones"
    else
        print_status 1 "  ‚îî‚îÄ PostgreSQL NO acepta conexiones"
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "PostgreSQL NO est√° corriendo"
    print_info "  ‚îî‚îÄ Ejecuta: docker-compose up -d"
    ERRORS=$((ERRORS + 1))
fi

if docker ps | grep -q "rustfs"; then
    print_status 0 "RustFS est√° corriendo"
    
    # Verificar conectividad
    if curl -s http://localhost:9000/minio/health/live > /dev/null 2>&1; then
        print_status 0 "  ‚îî‚îÄ RustFS acepta conexiones"
    else
        print_warning "  ‚îî‚îÄ RustFS puede estar inicializ√°ndose..."
    fi
else
    print_status 1 "RustFS NO est√° corriendo"
    print_info "  ‚îî‚îÄ Ejecuta: docker-compose up -d"
    ERRORS=$((ERRORS + 1))
fi

# Buscar contenedor de Airflow scheduler
AIRFLOW_SCHEDULER=$(docker ps --filter "name=scheduler" --format "{{.Names}}" 2>/dev/null | head -1)

if [ -n "$AIRFLOW_SCHEDULER" ]; then
    print_status 0 "Airflow Scheduler est√° corriendo ($AIRFLOW_SCHEDULER)"
else
    print_status 1 "Airflow Scheduler NO est√° corriendo"
    print_info "  ‚îî‚îÄ Ejecuta: cd airflow && astro dev start"
    ERRORS=$((ERRORS + 1))
fi

echo ""

# 3. Verificar red Docker
echo "3Ô∏è‚É£  Verificando red Docker..."
echo ""

if docker network inspect airflow_9558a3_airflow > /dev/null 2>&1; then
    print_status 0 "Red 'airflow_9558a3_airflow' existe"
    
    # Verificar que PostgreSQL est√° en la red
    if docker network inspect airflow_9558a3_airflow 2>/dev/null | grep -q "postgresql"; then
        print_status 0 "  ‚îî‚îÄ PostgreSQL en la red"
    else
        print_status 1 "  ‚îî‚îÄ PostgreSQL NO est√° en la red"
        ERRORS=$((ERRORS + 1))
    fi
    
    # Verificar que RustFS est√° en la red
    if docker network inspect airflow_9558a3_airflow 2>/dev/null | grep -q "rustfs"; then
        print_status 0 "  ‚îî‚îÄ RustFS en la red"
    else
        print_status 1 "  ‚îî‚îÄ RustFS NO est√° en la red"
        ERRORS=$((ERRORS + 1))
    fi
else
    print_status 1 "Red 'airflow_9558a3_airflow' NO existe"
    print_info "  ‚îî‚îÄ La red se crea autom√°ticamente al iniciar Airflow"
    ERRORS=$((ERRORS + 1))
fi

echo ""

# 4. Verificar bucket en RustFS
echo "4Ô∏è‚É£  Verificando bucket en RustFS..."
echo ""

if docker ps | grep -q "rustfs"; then
    # Usar Python para verificar el bucket (en vez de mc que no est√° instalado)
    BUCKET_CHECK=$(python3 -c "
import boto3
from botocore.client import Config
try:
    s3 = boto3.client('s3', 
        endpoint_url='http://localhost:9000',
        aws_access_key_id='admin',
        aws_secret_access_key='muceim-duckduck.2025!',
        config=Config(signature_version='s3v4'),
        region_name='us-east-1')
    buckets = [b['Name'] for b in s3.list_buckets()['Buckets']]
    if 'mitma' in buckets:
        print('OK')
    else:
        print('NOT_FOUND')
except Exception as e:
    print(f'ERROR:{e}')
" 2>&1)
    
    if [ "$BUCKET_CHECK" = "OK" ]; then
        print_status 0 "Bucket 'mitma' existe en RustFS"
    else
        print_status 1 "Bucket 'mitma' NO existe en RustFS"
        print_info "  ‚îî‚îÄ Detalle: $BUCKET_CHECK"
        print_info "  ‚îî‚îÄ Ejecuta: python3 scripts/init_rustfs.py"
        ERRORS=$((ERRORS + 1))
    fi
fi

echo ""

# 5. Verificar base de datos PostgreSQL
echo "5Ô∏è‚É£  Verificando base de datos PostgreSQL..."
echo ""

if docker ps | grep -q "postgresql"; then
    if docker exec postgresql psql -U admin -d mitma -c "SELECT 1" > /dev/null 2>&1; then
        print_status 0 "Base de datos 'mitma' existe y es accesible"
    else
        print_status 1 "Base de datos 'mitma' NO es accesible"
        print_info "  ‚îî‚îÄ Verifica las credenciales en .env"
        ERRORS=$((ERRORS + 1))
    fi
fi

echo ""

# 6. Resumen
echo "=================================================================="
echo "  üìä RESUMEN DE VERIFICACI√ìN"
echo "=================================================================="
echo ""

if [ $ERRORS -eq 0 ]; then
    echo -e "${GREEN}‚úÖ Todas las verificaciones pasaron correctamente${NC}"
    echo ""
    echo "üöÄ Pr√≥ximos pasos:"
    echo ""
    echo "   1. Reconstruir Airflow (si no lo has hecho):"
    echo "      cd airflow && astro dev stop && astro dev start --build"
    echo ""
    echo "   2. Acceder a Airflow UI:"
    echo "      http://localhost:8080 (admin/admin)"
    echo ""
    echo "   3. Ejecutar DAG de prueba:"
    echo "      test_ducklake_connections"
    echo ""
    echo "   4. Verificar logs:"
    echo "      cd airflow && astro dev logs --follow"
    echo ""
else
    echo -e "${RED}‚ùå Se encontraron $ERRORS error(es)${NC}"
    echo ""
    echo "üìã Acciones requeridas:"
    echo ""
    echo "   1. Revisa los errores arriba marcados con ‚ùå"
    echo "   2. Consulta la documentaci√≥n: airflow/CONFIGURACION_DUCKLAKE.md"
    echo "   3. Verifica las variables de entorno en .env"
    echo ""
fi

echo "=================================================================="

exit $ERRORS
