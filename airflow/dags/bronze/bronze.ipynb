{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "install-deps",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: duckdb in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (1.4.2)\n",
                        "Requirement already satisfied: pandas in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (2.3.3)\n",
                        "Requirement already satisfied: python-dotenv in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (1.2.1)\n",
                        "Requirement already satisfied: requests in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (2.32.5)\n",
                        "Requirement already satisfied: boto3 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (1.41.5)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
                        "Requirement already satisfied: numpy>=1.22.4 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (2.5.0)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (3.11)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (3.4.4)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (2025.11.12)\n",
                        "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from boto3) (0.15.0)\n",
                        "Requirement already satisfied: botocore<1.42.0,>=1.41.5 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from boto3) (1.41.5)\n",
                        "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install duckdb pandas python-dotenv requests boto3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "imports-setup",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import duckdb\n",
                "import pandas as pd\n",
                "import os\n",
                "import requests\n",
                "import urllib.request\n",
                "import re\n",
                "from dotenv import load_dotenv\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "LAKE_LAYER = 'bronze'\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv('../../.env', override=True) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "cd8af5a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "RUSTFS_HOST = os.getenv('RUSTFS_HOST', 'localhost')\n",
                "RUSTFS_PORT = os.getenv('RUSTFS_PORT', '8080')\n",
                "RUSTFS_USER = os.getenv('RUSTFS_USER', 'admin')\n",
                "RUSTFS_PASSWORD = os.getenv('RUSTFS_PASSWORD', 'password')\n",
                "RUSTFS_BUCKET = os.getenv('RUSTFS_BUCKET', 'mitma')\n",
                "RUSTFS_SSL = os.getenv('RUSTFS_SSL', 'false')\n",
                "\n",
                "# Postgres Configuration\n",
                "POSTGRES_USER = os.getenv('POSTGRES_USER', 'postgres')\n",
                "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD', 'password')\n",
                "POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')\n",
                "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')\n",
                "POSTGRES_DB = os.getenv('POSTGRES_DB', 'muceim')\n",
                "\n",
                "# Construct S3 Endpoint with protocol\n",
                "S3_ENDPOINT = f\"{RUSTFS_HOST}:{RUSTFS_PORT}\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "duckdb-connection",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Connecting to RustFS at localhost:9000...\n",
                        "Attaching DuckLake with query: ATTACH 'ducklake:postgres:dbname=mitma host=localhost user=admin password=muceim-duckduck.2025! port=30432' AS ducklake (DATA_PATH 's3://mitma/');\n",
                        "DuckLake configured with Postgres catalog and RustFS storage.\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Connecting to RustFS at {S3_ENDPOINT}...\")\n",
                "\n",
                "# Initialize DuckDB Connection\n",
                "con = duckdb.connect()\n",
                "\n",
                "# Install and Load extensions\n",
                "con.execute(\"INSTALL httpfs;\")\n",
                "con.execute(\"LOAD httpfs;\")\n",
                "con.execute(\"INSTALL postgres;\")\n",
                "con.execute(\"LOAD postgres;\")\n",
                "con.execute(\"INSTALL ducklake;\")\n",
                "con.execute(\"LOAD ducklake;\")\n",
                "\n",
                "# Configure S3 Secrets for RustFS\n",
                "con.execute(f\"SET s3_endpoint='{S3_ENDPOINT}';\")\n",
                "con.execute(f\"SET s3_access_key_id='{RUSTFS_USER}';\")\n",
                "con.execute(f\"SET s3_secret_access_key='{RUSTFS_PASSWORD}';\")\n",
                "con.execute(f\"SET s3_use_ssl={RUSTFS_SSL};\")\n",
                "con.execute(\"SET s3_url_style='path';\")\n",
                "con.execute(\"SET preserve_insertion_order=false;\")\n",
                "con.execute(\"SET max_temp_directory_size='40GiB';\")\n",
                "\n",
                "\n",
                "# Attach DuckLake with Postgres Catalog\n",
                "postgres_connection_string = f\"dbname={POSTGRES_DB} host={POSTGRES_HOST} user={POSTGRES_USER} password={POSTGRES_PASSWORD} port={POSTGRES_PORT}\"\n",
                "attach_query = f\"ATTACH 'ducklake:postgres:{postgres_connection_string}' AS ducklake (DATA_PATH 's3://{RUSTFS_BUCKET}/');\"\n",
                "\n",
                "print(f\"Attaching DuckLake with query: {attach_query}\")\n",
                "con.execute(attach_query)\n",
                "con.execute(\"USE ducklake;\")\n",
                "\n",
                "print(\"DuckLake configured with Postgres catalog and RustFS storage.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "913c2c4a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import boto3\n",
                "from botocore.client import Config\n",
                "\n",
                "s3 = boto3.resource('s3',\n",
                "    endpoint_url=f'http://{RUSTFS_HOST}:{RUSTFS_PORT}',\n",
                "    aws_access_key_id=RUSTFS_USER,\n",
                "    aws_secret_access_key=RUSTFS_PASSWORD,\n",
                "    config=Config(signature_version='s3v4'),\n",
                "    verify=False\n",
                ")\n",
                "\n",
                "if (not s3.Bucket(RUSTFS_BUCKET).creation_date):\n",
                "    try:\n",
                "        s3.create_bucket(Bucket=RUSTFS_BUCKET)\n",
                "        print(f\"Bucket '{RUSTFS_BUCKET}' created.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error creating bucket: {e}\")\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "cleanup-all",
            "metadata": {},
            "outputs": [],
            "source": [
                "import boto3\n",
                "from botocore.client import Config\n",
                "\n",
                "def cleanup_mitma_system():\n",
                "    \"\"\"\n",
                "    Cleans up the MITMA system by resetting the metadata \n",
                "    in PostgreSQL and clearing the storage in RustFS.\n",
                "    \"\"\"\n",
                "    print(\"\\n[1/2] Resetting Metadata in PostgreSQL...\")\n",
                "    try:\n",
                "        SQL(\"DROP SCHEMA public CASCADE;\")\n",
                "        SQL(\"CREATE SCHEMA public;\")\n",
                "        SQL(\"GRANT ALL ON SCHEMA public TO postgres;\")\n",
                "        SQL(\"GRANT ALL ON SCHEMA public TO public;\")\n",
                "        print(\"  ✓ Schema 'public' reseted.\")\n",
                "    except Exception as e:\n",
                "        print(f\"  ❌ Error resetting Postgres: {e}\")\n",
                "        return # Paramos si falla la DB\n",
                "\n",
                "    print(\"\\n[2/2] Resetting Storage in RustFS...\")\n",
                "    try:\n",
                "        bucket = s3.Bucket(RUSTFS_BUCKET)\n",
                "\n",
                "        if not bucket.creation_date:\n",
                "            return\n",
                "        \n",
                "        # Borramos todo el contenido\n",
                "        bucket.objects.all().delete()\n",
                "        # Borramos el bucket\n",
                "        bucket.delete()\n",
                "        #recreamos el bucket\n",
                "        s3.create_bucket(Bucket=RUSTFS_BUCKET)\n",
                "        print(f\"  ✓ Bucket '{RUSTFS_BUCKET}' recreated.\")\n",
                "    except Exception as e:\n",
                "        print(f\"  ❌ Error cleaning RustFS: {e}\")\n",
                "\n",
                "    print(\"\\n✅ MITMA SYSTEM RESETED.\")\n",
                "\n",
                "\n",
                "# Uncomment to run cleanup:\n",
                "# cleanup_mitma_system()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "helper-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def SQL(query):\n",
                "    \"\"\"Execute a SQL query and return the result as a Pandas DataFrame.\"\"\"\n",
                "    try:\n",
                "        return con.execute(query).fetchdf()\n",
                "    except Exception as e:\n",
                "        print(f\"Error executing query: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "url-helper",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_mitma_urls(dataset, zone_type, start_date, end_date):\n",
                "    \"\"\"\n",
                "    Fetches MITMA URLs from RSS feed and filters by dataset, zone type, and date range.\n",
                "    \"\"\"\n",
                "    rss_url = \"https://movilidad-opendata.mitma.es/RSS.xml\"\n",
                "    \n",
                "    # Simple mapping: dataset -> (url_path, file_prefix)\n",
                "    dataset_map = {\n",
                "        \"od\": (\"viajes\", \"Viajes\"),\n",
                "        \"people_day\": (\"personas\", \"Personas_dia\"),\n",
                "        \"overnight_stay\": (\"pernoctaciones\", \"Pernoctaciones\")\n",
                "    }\n",
                "    \n",
                "    if zone_type not in [\"distritos\", \"municipios\", \"gau\"]:\n",
                "        raise ValueError(f\"Invalid zone_type: {zone_type}. Must be 'distritos', 'municipios', or 'gau'.\")\n",
                "    if dataset not in dataset_map:\n",
                "        raise ValueError(f\"Invalid dataset: {dataset}. Must be one of {list(dataset_map.keys())}.\")\n",
                "    \n",
                "    dataset_path, file_prefix = dataset_map[dataset]\n",
                "    \n",
                "    # Construct file pattern: {Prefix}_{zone} (GAU is uppercase in files)\n",
                "    zone_suffix = \"GAU\" if zone_type == \"gau\" else zone_type\n",
                "    file_pattern = f\"{file_prefix}_{zone_suffix}\"\n",
                "    \n",
                "    # Build dynamic regex pattern\n",
                "    # Pattern: https://.../por-{zone}/viajes/ficheros-diarios/YYYY-MM/YYYYMMDD_{FilePattern}.csv.gz\n",
                "    pattern = rf'(https?://[^\\s\"<>]*/estudios_basicos/por-{zone_type}/{dataset_path}/ficheros-diarios/\\d{{4}}-\\d{{2}}/(\\d{{8}})_{file_pattern}\\.csv\\.gz)'\n",
                "        \n",
                "    # Fetch RSS with User-Agent to avoid 403\n",
                "    req = urllib.request.Request(rss_url, headers={\"User-Agent\": \"MITMA-DuckLake-Loader\"})\n",
                "    txt = urllib.request.urlopen(req).read().decode(\"utf-8\", \"ignore\")\n",
                "    \n",
                "    # Find all matches (case-insensitive for por-gau vs por-GAU)\n",
                "    matches = re.findall(pattern, txt, re.I)\n",
                "    \n",
                "    # Remove duplicates using set (RSS often has duplicate entries)\n",
                "    unique_matches = list(set(matches))\n",
                "    \n",
                "    # Convert date range to comparable format\n",
                "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
                "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
                "    \n",
                "    # Filter by date range and sort\n",
                "    filtered_urls = []\n",
                "    for url, date_str in unique_matches:\n",
                "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
                "        if start_dt <= file_date <= end_dt:\n",
                "            filtered_urls.append((url, date_str))\n",
                "    \n",
                "    # Sort by date ascending\n",
                "    filtered_urls.sort(key=lambda x: x[1])\n",
                "    \n",
                "    # Extract just the URLs\n",
                "    urls = [url for url, _ in filtered_urls]\n",
                "    \n",
                "    print(f\"Found {len(urls)} URLs for {dataset} {zone_type} from {start_date} to {end_date}\")\n",
                "    \n",
                "    if not urls:\n",
                "        print(f\"WARNING: No URLs found. Check if data exists for the requested date range.\")\n",
                "    \n",
                "    return urls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "create-table-helper",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_and_merge_table(table_name, urls):\n",
                "    \"\"\"\n",
                "    Generic function to create table and merge data for any MITMA dataset.\n",
                "    Uses ALL columns from the CSV as merge keys (bronze layer pattern).\n",
                "\n",
                "    Parameters:\n",
                "    - dataset: 'od', 'people_day', 'overnight_stay'\n",
                "    - zone_type: 'distritos', 'municipios', 'gau'\n",
                "    - urls: list of URLs to load\n",
                "    \"\"\"\n",
                "    \n",
                "    table_name = f'{LAKE_LAYER}_{table_name}'\n",
                "    \n",
                "    # Convert list of URLs to a string representation for DuckDB list\n",
                "    url_list_str = \"[\" + \", \".join([f\"'{u}'\" for u in urls]) + \"]\"\n",
                "\n",
                "    # Step 1: Create table if not exists (using first file for schema inference)\n",
                "    SQL(f\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS {table_name} AS\n",
                "        SELECT \n",
                "            * EXCLUDE (filename),\n",
                "            CURRENT_TIMESTAMP AS loaded_at,\n",
                "            filename AS source_file\n",
                "        FROM read_csv(\n",
                "            {url_list_str},\n",
                "            filename = true,\n",
                "            all_varchar = true\n",
                "        )\n",
                "        LIMIT 0;\n",
                "    \"\"\")\n",
                "    \n",
                "    # Get column names from the table (excluding audit columns)\n",
                "    columns_df = SQL(f\"\"\"\n",
                "        SELECT column_name \n",
                "        FROM information_schema.columns \n",
                "        WHERE table_name = '{table_name}'\n",
                "        AND column_name NOT IN ('loaded_at', 'source_file')\n",
                "        ORDER BY ordinal_position;\n",
                "    \"\"\")\n",
                "    \n",
                "    merge_keys = columns_df['column_name'].tolist()\n",
                "    \n",
                "    # Build ON clause from all CSV columns\n",
                "    on_clause = \" AND \".join([f\"target.{key} = source.{key}\" for key in merge_keys])\n",
                "    \n",
                "    # Step 3: MERGE for idempotent incremental loads\n",
                "    SQL(f\"\"\"\n",
                "        MERGE INTO {table_name} AS target\n",
                "        USING (\n",
                "            SELECT \n",
                "                * EXCLUDE (filename),\n",
                "                CURRENT_TIMESTAMP AS loaded_at,\n",
                "                filename AS source_file\n",
                "            FROM read_csv(\n",
                "                {url_list_str},\n",
                "                filename = true,\n",
                "                all_varchar = true\n",
                "            )\n",
                "        ) AS source\n",
                "        ON {on_clause}\n",
                "        WHEN MATCHED THEN\n",
                "            UPDATE SET *\n",
                "        WHEN NOT MATCHED THEN\n",
                "            INSERT *;\n",
                "    \"\"\")\n",
                "    \n",
                "    print(f\"Table {table_name} merged successfully with {len(merge_keys)} key columns.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "b81d764a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_and_merge_table_from_json(table_name, url, key_columns=None):\n",
                "    \"\"\"\n",
                "    Generic function to create table and merge data from JSON API endpoint using DuckDB's read_json.\n",
                "    \n",
                "    Parameters:\n",
                "    - table_name: Name of the table to create/merge into\n",
                "    - url: URL that returns JSON data (array of objects)\n",
                "    - key_columns: List of column names to use as merge keys. If None, uses all columns.\n",
                "    \"\"\"\n",
                "    \n",
                "    table_name = f'{LAKE_LAYER}_{table_name}'\n",
                "    \n",
                "    print(f\"Fetching JSON data from {url}...\")\n",
                "    \n",
                "    # Step 1: Create table if not exists using DuckDB's read_json\n",
                "    SQL(f\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS {table_name} AS\n",
                "        SELECT \n",
                "            *,\n",
                "            CURRENT_TIMESTAMP AS loaded_at,\n",
                "            '{url}' AS source_url\n",
                "        FROM read_json('{url}', format='array')\n",
                "        LIMIT 0;\n",
                "    \"\"\")\n",
                "    \n",
                "    # Step 2: Get column names from the table (excluding audit columns)\n",
                "    columns_df = SQL(f\"\"\"\n",
                "        SELECT column_name \n",
                "        FROM information_schema.columns \n",
                "        WHERE table_name = '{table_name}'\n",
                "        AND column_name NOT IN ('loaded_at', 'source_url')\n",
                "        ORDER BY ordinal_position;\n",
                "    \"\"\")\n",
                "    \n",
                "    data_columns = columns_df['column_name'].tolist()\n",
                "    \n",
                "    # Step 3: Determine merge keys\n",
                "    if key_columns is None:\n",
                "        merge_keys = data_columns\n",
                "    else:\n",
                "        merge_keys = key_columns\n",
                "        # Validate that key columns exist\n",
                "        missing_keys = [k for k in merge_keys if k not in data_columns]\n",
                "        if missing_keys:\n",
                "            raise ValueError(f\"Key columns {missing_keys} not found in data. Available columns: {data_columns}\")\n",
                "    \n",
                "    print(f\"Using merge keys: {merge_keys}\")\n",
                "    \n",
                "    # Step 4: Build ON clause\n",
                "    on_clause = \" AND \".join([f'target.\"{key}\" = source.\"{key}\"' for key in merge_keys])\n",
                "    \n",
                "    # Step 5: MERGE for idempotent incremental loads\n",
                "    merge_query = f\"\"\"\n",
                "        MERGE INTO {table_name} AS target\n",
                "        USING (\n",
                "            SELECT \n",
                "                *,\n",
                "                CURRENT_TIMESTAMP AS loaded_at,\n",
                "                '{url}' AS source_url\n",
                "            FROM read_json('{url}', format='array')\n",
                "        ) AS source\n",
                "        ON {on_clause}\n",
                "        WHEN MATCHED THEN\n",
                "            UPDATE SET *\n",
                "        WHEN NOT MATCHED THEN\n",
                "            INSERT *;\n",
                "    \"\"\"\n",
                "    \n",
                "    SQL(merge_query)\n",
                "    \n",
                "    # Get row count\n",
                "    count_result = SQL(f\"SELECT COUNT(*) as count FROM {table_name}\")\n",
                "    row_count = count_result.iloc[0, 0]\n",
                "    \n",
                "    print(f\"Table {table_name} merged successfully with {len(merge_keys)} key columns. Total rows: {row_count}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "load-od-matrices",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_od_matrices(type=\"districts\", start_date='2022-03-01', end_date='2022-03-03'):\n",
                "    \"\"\"\n",
                "    Load OD matrices for the specified type and date range.\n",
                "    \"\"\"\n",
                "    table_name = 'mitma_od'\n",
                "    urls = get_mitma_urls(dataset, type, start_date, end_date)\n",
                "    create_and_merge_table(table_name, urls)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "load-people-day",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_people_day(type=\"districts\", start_date='2022-03-01', end_date='2022-03-03'):\n",
                "    \"\"\"\n",
                "    Load people_day data for a specific type and date range.\n",
                "    \"\"\"\n",
                "    table_name = 'mitma_people_day'\n",
                "    urls = get_mitma_urls(dataset, type, start_date, end_date)\n",
                "    create_and_merge_table(table_name, urls)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "load-overnight-stay",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_overnight_stay(type=\"districts\", start_date='2022-03-01', end_date='2022-03-03'):\n",
                "    \"\"\"\n",
                "    Load overnight stay data for a specific type and date range.\n",
                "    \"\"\"\n",
                "    table_name = 'mitma_overnight_stay'\n",
                "    urls = get_mitma_urls(dataset, type, start_date, end_date)\n",
                "    create_and_merge_table(table_name, urls)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "verification",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DuckDB Version: v1.4.2\n",
                        "Tables in DuckLake:\n",
                        "                                      name\n",
                        "0                      bronze_ine_empresas\n",
                        "1            bronze_ine_empresas_municipio\n",
                        "2                    bronze_ine_municipios\n",
                        "3                   bronze_mitma_distritos\n",
                        "4                         bronze_mitma_gau\n",
                        "5               bronze_mitma_ine_relations\n",
                        "6                  bronze_mitma_municipios\n",
                        "7                bronze_mitma_od_distritos\n",
                        "8                      bronze_mitma_od_gau\n",
                        "9               bronze_mitma_od_municipios\n",
                        "10   bronze_mitma_overnight_stay_distritos\n",
                        "11         bronze_mitma_overnight_stay_gau\n",
                        "12  bronze_mitma_overnight_stay_municipios\n",
                        "13       bronze_mitma_people_day_distritos\n",
                        "14             bronze_mitma_people_day_gau\n",
                        "15      bronze_mitma_people_day_municipios\n",
                        "16                          ine_municipios\n"
                    ]
                }
            ],
            "source": [
                "# Verify connection\n",
                "print(\"DuckDB Version:\", SQL(\"SELECT version();\").iloc[0,0])\n",
                "\n",
                "# Check tables\n",
                "print(\"Tables in DuckLake:\")\n",
                "print(SQL(\"SHOW TABLES;\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "dfc2f499",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>fecha</th>\n",
                            "      <th>periodo</th>\n",
                            "      <th>origen</th>\n",
                            "      <th>destino</th>\n",
                            "      <th>distancia</th>\n",
                            "      <th>actividad_origen</th>\n",
                            "      <th>actividad_destino</th>\n",
                            "      <th>estudio_origen_posible</th>\n",
                            "      <th>estudio_destino_posible</th>\n",
                            "      <th>residencia</th>\n",
                            "      <th>renta</th>\n",
                            "      <th>edad</th>\n",
                            "      <th>sexo</th>\n",
                            "      <th>viajes</th>\n",
                            "      <th>viajes_km</th>\n",
                            "      <th>loaded_at</th>\n",
                            "      <th>source_file</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>18</td>\n",
                            "      <td>0200306</td>\n",
                            "      <td>0200304</td>\n",
                            "      <td>0.5-2</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>02</td>\n",
                            "      <td>10-15</td>\n",
                            "      <td>0-25</td>\n",
                            "      <td>hombre</td>\n",
                            "      <td>7.314</td>\n",
                            "      <td>12.617</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>02</td>\n",
                            "      <td>0200308</td>\n",
                            "      <td>0200307</td>\n",
                            "      <td>2-10</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>02</td>\n",
                            "      <td>10-15</td>\n",
                            "      <td>0-25</td>\n",
                            "      <td>mujer</td>\n",
                            "      <td>9.675</td>\n",
                            "      <td>21.203</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>17</td>\n",
                            "      <td>0305905</td>\n",
                            "      <td>03005_AM</td>\n",
                            "      <td>2-10</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>&lt;10</td>\n",
                            "      <td>0-25</td>\n",
                            "      <td>mujer</td>\n",
                            "      <td>10.296</td>\n",
                            "      <td>72.003</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>15</td>\n",
                            "      <td>0311902</td>\n",
                            "      <td>0301404</td>\n",
                            "      <td>0.5-2</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>10-15</td>\n",
                            "      <td>25-45</td>\n",
                            "      <td>mujer</td>\n",
                            "      <td>3.996</td>\n",
                            "      <td>7.662</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>11</td>\n",
                            "      <td>0306301</td>\n",
                            "      <td>03026_AM</td>\n",
                            "      <td>2-10</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>&lt;10</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>5.224</td>\n",
                            "      <td>41.202</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>07</td>\n",
                            "      <td>03011</td>\n",
                            "      <td>0303102</td>\n",
                            "      <td>0.5-2</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>10-15</td>\n",
                            "      <td>45-65</td>\n",
                            "      <td>mujer</td>\n",
                            "      <td>6.172</td>\n",
                            "      <td>7.305</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0308202</td>\n",
                            "      <td>03042</td>\n",
                            "      <td>2-10</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>&lt;10</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>2.027</td>\n",
                            "      <td>9.913</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>05</td>\n",
                            "      <td>0304902</td>\n",
                            "      <td>03055</td>\n",
                            "      <td>2-10</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>&lt;10</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>NA</td>\n",
                            "      <td>2.992</td>\n",
                            "      <td>28.929</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>11</td>\n",
                            "      <td>0306501</td>\n",
                            "      <td>0306502</td>\n",
                            "      <td>0.5-2</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>03</td>\n",
                            "      <td>10-15</td>\n",
                            "      <td>45-65</td>\n",
                            "      <td>mujer</td>\n",
                            "      <td>22.668</td>\n",
                            "      <td>24.994</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>20230301</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0820501</td>\n",
                            "      <td>0820502</td>\n",
                            "      <td>0.5-2</td>\n",
                            "      <td>frecuente</td>\n",
                            "      <td>casa</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>08</td>\n",
                            "      <td>&gt;15</td>\n",
                            "      <td>25-45</td>\n",
                            "      <td>hombre</td>\n",
                            "      <td>36.323</td>\n",
                            "      <td>49.042</td>\n",
                            "      <td>2025-12-02 18:31:02.395660+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/estudios_b...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      fecha periodo   origen   destino distancia actividad_origen  \\\n",
                            "0  20230301      18  0200306   0200304     0.5-2        frecuente   \n",
                            "1  20230301      02  0200308   0200307      2-10        frecuente   \n",
                            "2  20230301      17  0305905  03005_AM      2-10        frecuente   \n",
                            "3  20230301      15  0311902   0301404     0.5-2        frecuente   \n",
                            "4  20230301      11  0306301  03026_AM      2-10        frecuente   \n",
                            "5  20230301      07    03011   0303102     0.5-2        frecuente   \n",
                            "6  20230301      21  0308202     03042      2-10        frecuente   \n",
                            "7  20230301      05  0304902     03055      2-10        frecuente   \n",
                            "8  20230301      11  0306501   0306502     0.5-2        frecuente   \n",
                            "9  20230301      21  0820501   0820502     0.5-2        frecuente   \n",
                            "\n",
                            "  actividad_destino estudio_origen_posible estudio_destino_posible residencia  \\\n",
                            "0              casa                     no                      no         02   \n",
                            "1              casa                     no                      no         02   \n",
                            "2              casa                     no                      no         03   \n",
                            "3              casa                     no                      no         03   \n",
                            "4              casa                     no                      no         03   \n",
                            "5              casa                     no                      no         03   \n",
                            "6              casa                     no                      no         03   \n",
                            "7              casa                     no                      no         03   \n",
                            "8              casa                     no                      no         03   \n",
                            "9              casa                     no                      no         08   \n",
                            "\n",
                            "   renta   edad    sexo  viajes viajes_km                        loaded_at  \\\n",
                            "0  10-15   0-25  hombre   7.314    12.617 2025-12-02 18:31:02.395660+01:00   \n",
                            "1  10-15   0-25   mujer   9.675    21.203 2025-12-02 18:31:02.395660+01:00   \n",
                            "2    <10   0-25   mujer  10.296    72.003 2025-12-02 18:31:02.395660+01:00   \n",
                            "3  10-15  25-45   mujer   3.996     7.662 2025-12-02 18:31:02.395660+01:00   \n",
                            "4    <10     NA      NA   5.224    41.202 2025-12-02 18:31:02.395660+01:00   \n",
                            "5  10-15  45-65   mujer   6.172     7.305 2025-12-02 18:31:02.395660+01:00   \n",
                            "6    <10     NA      NA   2.027     9.913 2025-12-02 18:31:02.395660+01:00   \n",
                            "7    <10     NA      NA   2.992    28.929 2025-12-02 18:31:02.395660+01:00   \n",
                            "8  10-15  45-65   mujer  22.668    24.994 2025-12-02 18:31:02.395660+01:00   \n",
                            "9    >15  25-45  hombre  36.323    49.042 2025-12-02 18:31:02.395660+01:00   \n",
                            "\n",
                            "                                         source_file  \n",
                            "0  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "1  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "2  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "3  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "4  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "5  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "6  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "7  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "8  https://movilidad-opendata.mitma.es/estudios_b...  \n",
                            "9  https://movilidad-opendata.mitma.es/estudios_b...  "
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "SQL(\"\"\"\n",
                "    SELECT * \n",
                "    FROM bronze_mitma_od_distritos \n",
                "    USING SAMPLE 0.01 % (BERNOULLI)\n",
                "    LIMIT 10\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "d4c44c58",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: requests in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (2.32.5)\n",
                        "Requirement already satisfied: geopandas in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (1.0.1)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (2025.11.12)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (2.5.0)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from requests) (3.11)\n",
                        "Requirement already satisfied: shapely>=2.0.0 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (2.1.2)\n",
                        "Requirement already satisfied: pyproj>=3.3.0 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (3.7.1)\n",
                        "Requirement already satisfied: pyogrio>=0.7.2 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (0.11.1)\n",
                        "Requirement already satisfied: packaging in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (25.0)\n",
                        "Requirement already satisfied: pandas>=1.4.0 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (2.3.3)\n",
                        "Requirement already satisfied: numpy>=1.22 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from geopandas) (2.2.6)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
                        "Requirement already satisfied: six>=1.5 in /home/bgramaje/workspace/MUCEIM/bigdata/project/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install requests geopandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "4dbab1e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import urllib.request\n",
                "import re\n",
                "\n",
                "def get_mitma_zoning_urls(zone_type):\n",
                "    \"\"\"\n",
                "    Fetches MITMA Zoning URLs (Shapefiles + CSVs) from RSS feed using Regex.\n",
                "    Matches the style of 'get_mitma_urls' but for static zoning files.\n",
                "    \"\"\"\n",
                "    rss_url = \"https://movilidad-opendata.mitma.es/RSS.xml\"\n",
                "    \n",
                "    # Normalización de input\n",
                "    if zone_type not in [\"distritos\", \"municipios\", \"gau\"]:\n",
                "        raise ValueError(f\"Invalid zone_type: {zone_type}. Must be 'distritos', 'municipios', or 'gau'.\")\n",
                "\n",
                "    # Lógica de sufijos para construir el Regex\n",
                "    # Carpeta en URL: zonificacion_municipios | zonificacion_distritos | zonificacion_GAU\n",
                "    folder_suffix = \"GAU\" if zone_type == \"gau\" else zone_type\n",
                "    \n",
                "    # Sufijo en ficheros CSV: nombres_municipios | nombres_distritos | nombres_gaus\n",
                "    file_suffix = \"gaus\" if zone_type == \"gau\" else zone_type\n",
                "    \n",
                "    # --- REGEX PATTERNS ---\n",
                "    # 1. Pattern para componentes del Shapefile (.shp, .shx, .dbf, .prj)\n",
                "    # Busca URLs que contengan /zonificacion_{Suffix}/ y terminen en extensión de shapefile\n",
                "    shp_pattern = rf'(https?://[^\\s\"<>]*/zonificacion/zonificacion_{folder_suffix}/[^\"<>]+\\.(?:shp|shx|dbf|prj))'\n",
                "    \n",
                "    # 2. Pattern para CSVs auxiliares (nombres_*.csv, poblacion_*.csv)\n",
                "    # Busca URLs que contengan /zonificacion_{Suffix}/ y sean nombres_X.csv o poblacion_X.csv\n",
                "    csv_pattern = rf'(https?://[^\\s\"<>]*/zonificacion/zonificacion_{folder_suffix}/(?:nombres|poblacion)_{file_suffix}\\.csv)'\n",
                "\n",
                "    print(f\"📡 Scanning RSS for {zone_type} zoning files...\")\n",
                "\n",
                "    try:\n",
                "        # Fetch RSS with User-Agent\n",
                "        req = urllib.request.Request(rss_url, headers={\"User-Agent\": \"MITMA-DuckLake-Loader\"})\n",
                "        with urllib.request.urlopen(req) as response:\n",
                "            txt = response.read().decode(\"utf-8\", \"ignore\")\n",
                "        \n",
                "        # Find matches\n",
                "        shp_matches = re.findall(shp_pattern, txt, re.IGNORECASE)\n",
                "        csv_matches = re.findall(csv_pattern, txt, re.IGNORECASE)\n",
                "        \n",
                "        # Deduplicate\n",
                "        unique_shp = sorted(list(set(shp_matches)))\n",
                "        unique_csv = sorted(list(set(csv_matches)))\n",
                "        \n",
                "        # Organizar resultados\n",
                "        url_nombres = next((u for u in unique_csv if 'nombres' in u.lower()), None)\n",
                "        url_poblacion = next((u for u in unique_csv if 'poblacion' in u.lower()), None)\n",
                "        \n",
                "        if not unique_shp and not unique_csv:\n",
                "            print(\"WARNING: No zoning URLs found in RSS. The feed might have rotated them out.\")\n",
                "            # Opcional: Aquí podrías lanzar error o devolver fallback. \n",
                "            # Si quieres mantener el estilo estricto del otro script, devolvemos vacio.\n",
                "            return {}\n",
                "\n",
                "        print(f\"Found {len(unique_shp)} shapefile components and {len(unique_csv)} CSVs.\")\n",
                "        \n",
                "        return {\n",
                "            \"shp_components\": unique_shp,\n",
                "            \"nombres\": url_nombres,\n",
                "            \"poblacion\": url_poblacion\n",
                "        }\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"ERROR fetching RSS: {e}\")\n",
                "        return {}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "d85c4956",
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_id(series):\n",
                "    \"\"\"Normaliza ID a string limpio (sin .0, sin espacios).\"\"\"\n",
                "    return series.astype(str).str.strip().str.replace(r'\\.0$', '', regex=True)\n",
                "\n",
                "def clean_poblacion(series):\n",
                "    \"\"\"Limpia enteros de población (quita puntos y decimales).\"\"\"\n",
                "    return (series.astype(str)\n",
                "            .str.replace('.', '', regex=False)\n",
                "            .str.replace(r'\\.0$', '', regex=True)\n",
                "            .apply(pd.to_numeric, errors='coerce')\n",
                "            .fillna(0).astype(int))\n",
                "\n",
                "def get_mitma_zoning_dataset(zone_type='municipios'):\n",
                "    \"\"\"\n",
                "    Orquesta la descarga, limpieza y fusión de datos maestros.\n",
                "    Retorna un GeoDataFrame listo para ingesta.\n",
                "    \"\"\"\n",
                "    urls = get_mitma_zoning_urls(zone_type)\n",
                "    \n",
                "    print(f\"🚀 Generando dataset maestro para: {zone_type.upper()}\")\n",
                "    \n",
                "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
                "        print(\"   ⬇️  Descargando geometrías...\")\n",
                "        shp_local_path = None\n",
                "        \n",
                "        for url in urls['shp_components']:\n",
                "            filename = url.split('/')[-1]\n",
                "            try:\n",
                "                r = requests.get(url, timeout=15)\n",
                "                if r.status_code == 200:\n",
                "                    local_p = os.path.join(tmp_dir, filename)\n",
                "                    with open(local_p, 'wb') as f:\n",
                "                        f.write(r.content)\n",
                "                    if filename.endswith('.shp'):\n",
                "                        shp_local_path = local_p\n",
                "            except Exception as e:\n",
                "                print(f\"      ⚠️ Error bajando {filename}: {e}\")\n",
                "\n",
                "        if not shp_local_path:\n",
                "            print(\"❌ Error: No se pudo descargar el archivo .shp principal.\")\n",
                "            return None\n",
                "\n",
                "        gdf = gpd.read_file(shp_local_path)\n",
                "        \n",
                "        id_col = next((c for c in gdf.columns if c.upper() in ['ID', 'CODIGO', 'ZONA', 'COD_GAU']), 'ID')\n",
                "        gdf['ID'] = clean_id(gdf[id_col])\n",
                "        \n",
                "        gdf['geometry'] = gdf['geometry'].apply(make_valid)\n",
                "        if gdf.crs and gdf.crs.to_string() != \"EPSG:4326\":\n",
                "            gdf = gdf.to_crs(\"EPSG:4326\")\n",
                "\n",
                "        print(\"   🔗 Integrando metadatos (Nombres y Población)...\")\n",
                "        df_aux = pd.DataFrame(columns=['ID'])\n",
                "        \n",
                "        aux_config = [\n",
                "            {\n",
                "                'type': 'nombres', \n",
                "                'url': urls['nombres'], \n",
                "                'header': 0, \n",
                "                'cols': ['ID', 'Nombre']\n",
                "            },\n",
                "            {\n",
                "                'type': 'poblacion', \n",
                "                'url': urls['poblacion'], \n",
                "                'header': None, \n",
                "                'cols': ['ID', 'Poblacion']\n",
                "            }\n",
                "        ]\n",
                "\n",
                "        for cfg in aux_config:\n",
                "            try:\n",
                "                r = requests.get(cfg['url'], timeout=10)\n",
                "                if r.status_code == 200:\n",
                "                    # Leer CSV crudo\n",
                "                    df_t = pd.read_csv(\n",
                "                        io.BytesIO(r.content), \n",
                "                        sep='|', \n",
                "                        header=cfg['header'], \n",
                "                        dtype=str, \n",
                "                        engine='python'\n",
                "                    )\n",
                "                    \n",
                "\n",
                "                    if len(df_t.columns) >= 3:\n",
                "                        df_t = df_t.iloc[:, [1, 2]]\n",
                "                    elif len(df_t.columns) == 2:\n",
                "                        df_t = df_t.iloc[:, [0, 1]]\n",
                "                    \n",
                "                    df_t.columns = cfg['cols']\n",
                "                    \n",
                "                    df_t['ID'] = clean_id(df_t['ID'])\n",
                "                    df_t = df_t.drop_duplicates(subset=['ID'])\n",
                "                    \n",
                "                    if cfg['type'] == 'poblacion':\n",
                "                        df_t['Poblacion'] = clean_poblacion(df_t['Poblacion'])\n",
                "\n",
                "                    if df_aux.empty:\n",
                "                        df_aux = df_t\n",
                "                    else:\n",
                "                        df_aux = df_aux.merge(df_t, on='ID', how='outer')\n",
                "                        \n",
                "                    print(f\"      ✓ {cfg['type'].capitalize()} OK\")\n",
                "            except Exception as e:\n",
                "                print(f\"      ⚠️ Fallo procesando {cfg['type']}: {e}\")\n",
                "\n",
                "        # --- C. Merge Final ---\n",
                "        if not df_aux.empty:\n",
                "            gdf = gdf.merge(df_aux, on='ID', how='left')\n",
                "            \n",
                "            if 'Nombre' in gdf.columns: \n",
                "                gdf['Nombre'] = gdf['Nombre'].fillna(gdf['ID'])\n",
                "            if 'Poblacion' in gdf.columns: \n",
                "                gdf['Poblacion'] = gdf['Poblacion'].fillna(0).astype(int)\n",
                "\n",
                "        cols = ['ID', 'Nombre', 'Poblacion', 'geometry']\n",
                "        final_cols = [c for c in cols if c in gdf.columns] + [c for c in gdf.columns if c not in cols]\n",
                "        gdf = gdf[final_cols]\n",
                "\n",
                "        print(f\"✅ Dataset generado: {len(gdf)} registros.\")\n",
                "        return gdf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "d551de38",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_zonificacion(type):\n",
                "    \"\"\"\n",
                "    Load zonification data into DuckDB for the specified type.\n",
                "    \"\"\"\n",
                "    df = get_mitma_zoning_dataset(type)\n",
                "    \n",
                "    if df is None or df.empty:\n",
                "        print(f\"No data to load for {type}\")\n",
                "        return\n",
                "    \n",
                "    # Convert all columns to string (including geometry)\n",
                "    for col in df.columns:\n",
                "        df[col] = df[col].astype(str)\n",
                "    \n",
                "    table_name = f'{LAKE_LAYER}_mitma_{type}'\n",
                "    \n",
                "    con.register('temp_zonificacion', df)\n",
                "    \n",
                "    SQL(f\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS {table_name} AS\n",
                "        SELECT\n",
                "            *,\n",
                "            CURRENT_TIMESTAMP AS loaded_at,\n",
                "        FROM temp_zonificacion\n",
                "        LIMIT 0;\n",
                "    \"\"\")\n",
                "    \n",
                "    merge_key = 'ID'\n",
                "    \n",
                "    SQL(f\"\"\"\n",
                "        MERGE INTO {table_name} AS target\n",
                "        USING (\n",
                "            SELECT\n",
                "                *,\n",
                "                CURRENT_TIMESTAMP AS loaded_at,\n",
                "            FROM temp_zonificacion\n",
                "        ) AS source\n",
                "        ON target.{merge_key} = source.{merge_key}\n",
                "        WHEN MATCHED THEN\n",
                "            UPDATE SET *\n",
                "        WHEN NOT MATCHED THEN\n",
                "            INSERT *;\n",
                "    \"\"\")\n",
                "    \n",
                "    con.unregister('temp_zonificacion')\n",
                "    \n",
                "    print(f\"Table {table_name} merged successfully with {len(df)} records.\")\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "065b2e72",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>ID</th>\n",
                            "      <th>Nombre</th>\n",
                            "      <th>Poblacion</th>\n",
                            "      <th>geometry</th>\n",
                            "      <th>loaded_at</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>01001</td>\n",
                            "      <td>Alegría-Dulantzi</td>\n",
                            "      <td>29250</td>\n",
                            "      <td>POINT (-2.511272 42.829065)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>01002</td>\n",
                            "      <td>Amurrio</td>\n",
                            "      <td>103070</td>\n",
                            "      <td>POINT (-2.971689 43.025464)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>01004_AM</td>\n",
                            "      <td>Artziniega agregacion de municipios</td>\n",
                            "      <td>30050</td>\n",
                            "      <td>POINT (-3.076283 43.150032)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>01009_AM</td>\n",
                            "      <td>Asparrena agregacion de municipios</td>\n",
                            "      <td>45990</td>\n",
                            "      <td>POINT (-2.430988 42.883162)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>01010</td>\n",
                            "      <td>Ayala/Aiara</td>\n",
                            "      <td>29510</td>\n",
                            "      <td>POINT (-3.078215 43.075551)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>01017_AM</td>\n",
                            "      <td>Campezo/Kanpezu agregacion de municipios</td>\n",
                            "      <td>43140</td>\n",
                            "      <td>POINT (-2.435706 42.700123)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>01028_AM</td>\n",
                            "      <td>Labastida/Bastida agregacion de municipios</td>\n",
                            "      <td>75150</td>\n",
                            "      <td>POINT (-2.687343 42.60083)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>01036</td>\n",
                            "      <td>Laudio/Llodio</td>\n",
                            "      <td>180090</td>\n",
                            "      <td>POINT (-2.977515 43.13818)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>01043</td>\n",
                            "      <td>Oyón-Oion</td>\n",
                            "      <td>34180</td>\n",
                            "      <td>POINT (-2.432799 42.544579)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>01047_AM</td>\n",
                            "      <td>Erriberabeitia agregacion de municipios</td>\n",
                            "      <td>37710</td>\n",
                            "      <td>POINT (-3.074379 42.826092)</td>\n",
                            "      <td>2025-12-02 18:32:19.196526+01:00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         ID                                      Nombre Poblacion  \\\n",
                            "0     01001                            Alegría-Dulantzi     29250   \n",
                            "1     01002                                     Amurrio    103070   \n",
                            "2  01004_AM         Artziniega agregacion de municipios     30050   \n",
                            "3  01009_AM          Asparrena agregacion de municipios     45990   \n",
                            "4     01010                                 Ayala/Aiara     29510   \n",
                            "5  01017_AM    Campezo/Kanpezu agregacion de municipios     43140   \n",
                            "6  01028_AM  Labastida/Bastida agregacion de municipios     75150   \n",
                            "7     01036                               Laudio/Llodio    180090   \n",
                            "8     01043                                   Oyón-Oion     34180   \n",
                            "9  01047_AM     Erriberabeitia agregacion de municipios     37710   \n",
                            "\n",
                            "                      geometry                        loaded_at  \n",
                            "0  POINT (-2.511272 42.829065) 2025-12-02 18:32:19.196526+01:00  \n",
                            "1  POINT (-2.971689 43.025464) 2025-12-02 18:32:19.196526+01:00  \n",
                            "2  POINT (-3.076283 43.150032) 2025-12-02 18:32:19.196526+01:00  \n",
                            "3  POINT (-2.430988 42.883162) 2025-12-02 18:32:19.196526+01:00  \n",
                            "4  POINT (-3.078215 43.075551) 2025-12-02 18:32:19.196526+01:00  \n",
                            "5  POINT (-2.435706 42.700123) 2025-12-02 18:32:19.196526+01:00  \n",
                            "6   POINT (-2.687343 42.60083) 2025-12-02 18:32:19.196526+01:00  \n",
                            "7   POINT (-2.977515 43.13818) 2025-12-02 18:32:19.196526+01:00  \n",
                            "8  POINT (-2.432799 42.544579) 2025-12-02 18:32:19.196526+01:00  \n",
                            "9  POINT (-3.074379 42.826092) 2025-12-02 18:32:19.196526+01:00  "
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "SQL(\"\"\"\n",
                "    SELECT *\n",
                "    FROM bronze_mitma_gau\n",
                "    LIMIT 10\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "f8de755a",
            "metadata": {},
            "outputs": [],
            "source": [
                "table_name = \"mitma_ine_relations\"\n",
                "# create_and_merge_table(table_name, [\"https://movilidad-opendata.mitma.es/zonificacion/relacion_ine_zonificacionMitma.csv\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "747fcd4c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>seccion_ine</th>\n",
                            "      <th>distrito_ine</th>\n",
                            "      <th>municipio_ine</th>\n",
                            "      <th>distrito_mitma</th>\n",
                            "      <th>municipio_mitma</th>\n",
                            "      <th>gau_mitma</th>\n",
                            "      <th>loaded_at</th>\n",
                            "      <th>source_file</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0100101001</td>\n",
                            "      <td>0100101</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0100101002</td>\n",
                            "      <td>0100101</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>01001</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0100201001</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0100201002</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0100201003</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>0100201004</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>0100201005</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>0100201006</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>0100201007</td>\n",
                            "      <td>0100201</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>01002</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>0100301001</td>\n",
                            "      <td>0100301</td>\n",
                            "      <td>01003</td>\n",
                            "      <td>01058_AM</td>\n",
                            "      <td>01058_AM</td>\n",
                            "      <td>01058_AM</td>\n",
                            "      <td>2025-12-02 20:53:25.217176+01:00</td>\n",
                            "      <td>https://movilidad-opendata.mitma.es/zonificaci...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  seccion_ine distrito_ine municipio_ine distrito_mitma municipio_mitma  \\\n",
                            "0  0100101001      0100101         01001          01001           01001   \n",
                            "1  0100101002      0100101         01001          01001           01001   \n",
                            "2  0100201001      0100201         01002          01002           01002   \n",
                            "3  0100201002      0100201         01002          01002           01002   \n",
                            "4  0100201003      0100201         01002          01002           01002   \n",
                            "5  0100201004      0100201         01002          01002           01002   \n",
                            "6  0100201005      0100201         01002          01002           01002   \n",
                            "7  0100201006      0100201         01002          01002           01002   \n",
                            "8  0100201007      0100201         01002          01002           01002   \n",
                            "9  0100301001      0100301         01003       01058_AM        01058_AM   \n",
                            "\n",
                            "  gau_mitma                        loaded_at  \\\n",
                            "0     01001 2025-12-02 20:53:25.217176+01:00   \n",
                            "1     01001 2025-12-02 20:53:25.217176+01:00   \n",
                            "2     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "3     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "4     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "5     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "6     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "7     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "8     01002 2025-12-02 20:53:25.217176+01:00   \n",
                            "9  01058_AM 2025-12-02 20:53:25.217176+01:00   \n",
                            "\n",
                            "                                         source_file  \n",
                            "0  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "1  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "2  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "3  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "4  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "5  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "6  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "7  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "8  https://movilidad-opendata.mitma.es/zonificaci...  \n",
                            "9  https://movilidad-opendata.mitma.es/zonificaci...  "
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "SQL(\"\"\"\n",
                "    SELECT *\n",
                "    FROM bronze_mitma_ine_relations\n",
                "    LIMIT 10\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "44cd59e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_municipios_ine():\n",
                "    \"\"\"\n",
                "    Load municipios from INE datasource\n",
                "    \"\"\"\n",
                "    table_name = 'ine_municipios'\n",
                "    url = 'https://servicios.ine.es/wstempus/js/ES/VALORES_VARIABLE/19'\n",
                "    \n",
                "    # Use 'Id' as the primary key for municipios\n",
                "    create_and_merge_table_from_json(\n",
                "        table_name, \n",
                "        url,\n",
                "        ['Id']  # Assuming 'Id' is the unique identifier\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "1e648725",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_empresas_municipio_ine(year = 2023):\n",
                "    \"\"\"\n",
                "    Load empresas from INE datasource\n",
                "    \"\"\"\n",
                "    table_name = 'ine_empresas_municipio'\n",
                "    url = f'https://servicios.ine.es/wstempus/js/ES/DATOS_TABLA/4721?date={year}0101:{year}1231&Tv=40621:248341&Tv=selCri_2:on'\n",
                "    \n",
                "    # Use 'Id' as the primary key for municipios\n",
                "    create_and_merge_table_from_json(\n",
                "        table_name, \n",
                "        url,\n",
                "        ['COD']  # Assuming 'Id' is the unique identifier\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "7f9c67e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_poblacion_municipio_ine(year = 2023):\n",
                "    \"\"\"\n",
                "    Load empresas from INE datasource\n",
                "    \"\"\"\n",
                "    table_name = 'ine_poblacion_municipio'\n",
                "    url = f'https://servicios.ine.es/wstempus/js/ES/DATOS_TABLA/29005?date={year}0101:{year}1231&nult=1&det=2'\n",
                "    \n",
                "    # Use 'Id' as the primary key for municipios\n",
                "    create_and_merge_table_from_json(\n",
                "        table_name, \n",
                "        url,\n",
                "        ['COD']  # Assuming 'Id' is the unique identifier\n",
                "    ) \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "1702e7a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_renta_municipio_ine(year = 2023):\n",
                "    \"\"\"\n",
                "    Load empresas from INE datasource\n",
                "    \"\"\"\n",
                "    table_name = 'ine_renta_municipio'\n",
                "    url = f'https://servicios.ine.es/wstempus/js/ES/DATOS_TABLA/30896?date={year}0101'\n",
                "    \n",
                "    # Use 'Id' as the primary key for municipios\n",
                "    create_and_merge_table_from_json(\n",
                "        table_name, \n",
                "        url,\n",
                "        ['COD']  # Assuming 'Id' is the unique identifier\n",
                "    ) \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e8824c2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fetching JSON data from https://servicios.ine.es/wstempus/js/ES/DATOS_TABLA/30896?date=20230101...\n",
                        "Using merge keys: ['COD']\n",
                        "Table bronze_ine_renta_municipio merged successfully with 1 key columns. Total rows: 31444\n"
                    ]
                }
            ],
            "source": [
                "# load_municipios_ine()\n",
                "# load_empresas_municipio_ine()\n",
                "# load_poblacion_municipio_ine()\n",
                "# load_renta_municipio_ine()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "a0d7eb79",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>COD</th>\n",
                            "      <th>Nombre</th>\n",
                            "      <th>FK_Unidad</th>\n",
                            "      <th>FK_Escala</th>\n",
                            "      <th>Data</th>\n",
                            "      <th>loaded_at</th>\n",
                            "      <th>source_url</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>ADRH102301</td>\n",
                            "      <td>Abrera. Dato base. Renta neta media por persona.</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>ADRH102300</td>\n",
                            "      <td>Abrera. Dato base. Renta neta media por hogar.</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>ADRH9821769</td>\n",
                            "      <td>Abrera. Dato base. Media de la renta por unida...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>ADRH9612349</td>\n",
                            "      <td>Abrera. Dato base. Mediana de la renta por uni...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>ADRH9612348</td>\n",
                            "      <td>Abrera. Dato base. Renta mediana por hogar.</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>ADRH9612347</td>\n",
                            "      <td>Abrera. Dato base. Renta bruta media por perso...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>ADRH9612346</td>\n",
                            "      <td>Abrera. Dato base. Renta bruta media por hogar.</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>ADRH75855</td>\n",
                            "      <td>Abrera distrito 01. Dato base. Renta neta medi...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>ADRH75854</td>\n",
                            "      <td>Abrera distrito 01. Dato base. Renta neta medi...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>ADRH9807923</td>\n",
                            "      <td>Abrera distrito 01. Dato base. Media de la ren...</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...</td>\n",
                            "      <td>2025-12-02 22:59:14.396410+01:00</td>\n",
                            "      <td>https://servicios.ine.es/wstempus/js/ES/DATOS_...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           COD                                             Nombre  FK_Unidad  \\\n",
                            "0   ADRH102301  Abrera. Dato base. Renta neta media por persona.           7   \n",
                            "1   ADRH102300    Abrera. Dato base. Renta neta media por hogar.           7   \n",
                            "2  ADRH9821769  Abrera. Dato base. Media de la renta por unida...          7   \n",
                            "3  ADRH9612349  Abrera. Dato base. Mediana de la renta por uni...          7   \n",
                            "4  ADRH9612348       Abrera. Dato base. Renta mediana por hogar.           7   \n",
                            "5  ADRH9612347  Abrera. Dato base. Renta bruta media por perso...          7   \n",
                            "6  ADRH9612346   Abrera. Dato base. Renta bruta media por hogar.           7   \n",
                            "7    ADRH75855  Abrera distrito 01. Dato base. Renta neta medi...          7   \n",
                            "8    ADRH75854  Abrera distrito 01. Dato base. Renta neta medi...          7   \n",
                            "9  ADRH9807923  Abrera distrito 01. Dato base. Media de la ren...          7   \n",
                            "\n",
                            "   FK_Escala                                               Data  \\\n",
                            "0          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "1          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "2          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "3          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "4          1                                                 []   \n",
                            "5          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "6          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "7          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "8          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "9          1  [{'Fecha': 1672527600000, 'FK_TipoDato': 1, 'F...   \n",
                            "\n",
                            "                         loaded_at  \\\n",
                            "0 2025-12-02 22:59:14.396410+01:00   \n",
                            "1 2025-12-02 22:59:14.396410+01:00   \n",
                            "2 2025-12-02 22:59:14.396410+01:00   \n",
                            "3 2025-12-02 22:59:14.396410+01:00   \n",
                            "4 2025-12-02 22:59:14.396410+01:00   \n",
                            "5 2025-12-02 22:59:14.396410+01:00   \n",
                            "6 2025-12-02 22:59:14.396410+01:00   \n",
                            "7 2025-12-02 22:59:14.396410+01:00   \n",
                            "8 2025-12-02 22:59:14.396410+01:00   \n",
                            "9 2025-12-02 22:59:14.396410+01:00   \n",
                            "\n",
                            "                                          source_url  \n",
                            "0  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "1  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "2  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "3  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "4  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "5  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "6  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "7  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "8  https://servicios.ine.es/wstempus/js/ES/DATOS_...  \n",
                            "9  https://servicios.ine.es/wstempus/js/ES/DATOS_...  "
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "SQL(\"\"\"\n",
                "    SELECT *\n",
                "    FROM bronze_ine_renta_municipio\n",
                "    LIMIT 10\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbc3f4e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MITMA data insertion\n",
                "\n",
                "# import gc\n",
                "\n",
                "# start_date = '2022-03-01'\n",
                "# end_date = '2022-03-07'\n",
                "# types = ['distritos', 'municipios', 'gau']\n",
                "\n",
                "# for type in types:\n",
                "#     \"\"\"\n",
                "#     Load OD matrices, people day, and overnight stay data for a specific type and date range.\n",
                "#     \"\"\"\n",
                "#     load_od_matrices(type=type, start_date=start_date, end_date=end_date)\n",
                "#     load_people_day(type=type, start_date=start_date, end_date=end_date)\n",
                "#     load_overnight_stay(type=type, start_date=start_date, end_date=end_date)\n",
                "#     load_zonificacion(type=type)\n",
                "#     print(f\"--- Liberando memoria tras {type} ---\")\n",
                "#     gc.collect()  # Fuerza al recolector de basura de Python a limpiar objetos no usados"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
