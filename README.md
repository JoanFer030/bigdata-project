# ğŸš€ BigData Project - MITMA Data Pipeline

Proyecto de ingesta y procesamiento de datos de movilidad del Ministerio de Transportes, Movilidad y Agenda Urbana (MITMA) utilizando Apache Airflow, DuckDB/DuckLake, PostgreSQL y RustFS.

## ğŸ“‹ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APACHE AIRFLOW                            â”‚
â”‚                   (OrquestaciÃ³n)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DAGs: Bronze Layer (Ingesta de datos MITMA)        â”‚   â”‚
â”‚  â”‚         â†“                                            â”‚   â”‚
â”‚  â”‚  DuckDB + DuckLake Extension                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL     â”‚  â”‚     RustFS       â”‚
    â”‚   (Metadatos)    â”‚  â”‚   (Datos S3)     â”‚
    â”‚                  â”‚  â”‚                  â”‚
    â”‚  - CatÃ¡logo      â”‚  â”‚  - Parquet       â”‚
    â”‚  - Esquemas      â”‚  â”‚  - CSV           â”‚
    â”‚  - Tablas        â”‚  â”‚  - Delta         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Componentes

- **Apache Airflow** (Astronomer Runtime 3.1-5): OrquestaciÃ³n de pipelines
- **DuckDB + DuckLake**: Motor de consultas con arquitectura lake-house
- **PostgreSQL 15**: CatÃ¡logo de metadatos
- **RustFS/MinIO**: Object storage compatible con S3
- **Portainer**: GestiÃ³n de contenedores

## ğŸš€ Quick Start

### 1. Iniciar servicios

```bash
# Iniciar PostgreSQL, RustFS y Portainer
docker-compose up -d

# Iniciar Airflow (Astronomer)
cd airflow
astro dev start --build
```

### 2. Inicializar RustFS

```bash
# Crear bucket necesario para DuckLake
./scripts/init_rustfs.sh
```

### 3. Verificar conexiones

Accede a Airflow en http://localhost:8080 y ejecuta el DAG `test_ducklake_connections`

### 4. Acceder a servicios

- **Airflow UI**: http://localhost:8080 (admin/admin)
- **RustFS UI**: http://localhost:9001 (admin/muceim-duckduck.2025!)
- **Portainer**: http://localhost:9443
- **PostgreSQL**: localhost:30432 (admin/muceim-duckduck.2025!)

## ğŸ“š DocumentaciÃ³n

- [**ConfiguraciÃ³n DuckLake**](airflow/CONFIGURACION_DUCKLAKE.md) - GuÃ­a completa de configuraciÃ³n
- [**Airflow Settings**](airflow/airflow_settings.yaml) - Conexiones y variables
- [**Test Connections**](airflow/test_connections.py) - Script de verificaciÃ³n

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno (.env)

```bash
# PostgreSQL
POSTGRES_USER=admin
POSTGRES_PASSWORD=muceim-duckduck.2025!
POSTGRES_DB=mitma

# RustFS
RUSTFS_USER=admin
RUSTFS_PASSWORD=muceim-duckduck.2025!
RUSTFS_BUCKET=mitma
```

### Conexiones de Airflow

Ya configuradas en `airflow/airflow_settings.yaml`:

- `postgres_datos_externos` - PostgreSQL (catÃ¡logo)
- `rustfs_s3_conn` - RustFS (almacenamiento)

## ğŸ“¦ DAGs Disponibles

- `mitma_viajes_ingest` - Ingesta de datos de viajes origen-destino
- `mitma_pernoctaciones_ingest` - Ingesta de datos de pernoctaciones
- `mitma_personas_ingest` - Ingesta de datos de personas por dÃ­a
- `test_ducklake_connections` - VerificaciÃ³n de conexiones

## ğŸ› ï¸ Desarrollo

### Estructura del proyecto

```
bigdata-project/
â”œâ”€â”€ docker-compose.yml          # Servicios: PostgreSQL, RustFS, Portainer
â”œâ”€â”€ .env                        # Variables de entorno
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_rustfs.sh         # InicializaciÃ³n de RustFS
â””â”€â”€ airflow/
    â”œâ”€â”€ Dockerfile              # Imagen personalizada de Airflow
    â”œâ”€â”€ requirements.txt        # Dependencias Python
    â”œâ”€â”€ airflow_settings.yaml   # Conexiones y variables
    â”œâ”€â”€ test_connections.py     # Script de prueba
    â”œâ”€â”€ CONFIGURACION_DUCKLAKE.md  # DocumentaciÃ³n detallada
    â””â”€â”€ dags/
        â”œâ”€â”€ utils.py            # Utilidades comunes
        â”œâ”€â”€ dag_test_ducklake.py        # DAG de prueba
        â”œâ”€â”€ dag_bronze_mitma.py         # DAG de ingesta MITMA
        â””â”€â”€ bronze/
            â””â”€â”€ tasks/          # Tareas de ingesta
```

### Comandos Ãºtiles

```bash
# Reconstruir Airflow
cd airflow
astro dev stop
astro dev start --build

# Ver logs
astro dev logs --follow

# Ejecutar tests
astro dev run pytest

# Verificar conexiones
astro dev bash
python test_connections.py
```

## ğŸ› ResoluciÃ³n de Problemas

### Error: "Connection not found"

```bash
# Reiniciar Airflow para cargar airflow_settings.yaml
cd airflow
astro dev restart
```

### Error: "Could not connect to PostgreSQL"

```bash
# Verificar que PostgreSQL estÃ¡ corriendo
docker ps | grep postgresql

# Verificar red Docker
docker network inspect airflow_9558a3_airflow
```

### Error: "S3 connection failed"

```bash
# Verificar RustFS
docker ps | grep rustfs

# Reinicializar bucket
./scripts/init_rustfs.sh
```

Ver mÃ¡s detalles en [CONFIGURACION_DUCKLAKE.md](airflow/CONFIGURACION_DUCKLAKE.md)

## ğŸ“Š Uso en DAGs

```python
from utils import connect_datalake_from_airflow

@task
def ingest_data():
    # Conectar a DuckLake (PostgreSQL + RustFS)
    con = connect_datalake_from_airflow()
    
    try:
        # Crear tabla (metadatos en PostgreSQL)
        con.execute("""
            CREATE TABLE IF NOT EXISTS bronze_mitma_od (
                fecha TEXT,
                origen TEXT,
                destino TEXT,
                viajes TEXT
            );
        """)
        
        # Insertar datos (archivos en RustFS)
        con.execute("""
            INSERT INTO bronze_mitma_od
            SELECT * FROM read_csv('url_mitma.csv.gz');
        """)
        
    finally:
        con.close()
```

## ğŸ“ TODO

- [ ] Reconstruir contenedor de Airflow
- [ ] Inicializar bucket en RustFS
- [ ] Ejecutar DAG de prueba
- [ ] Actualizar DAGs existentes para usar `connect_datalake_from_airflow()`
- [ ] Implementar capa Silver
- [ ] Implementar capa Gold

## ğŸ¤ ContribuciÃ³n

Este es un proyecto acadÃ©mico para el MÃ¡ster en Big Data (MUCEIM).

## ğŸ“„ Licencia

MIT License

---

**Autor**: Bruno Gramaje  
**InstituciÃ³n**: MUCEIM - MÃ¡ster en Big Data  
**Fecha**: Diciembre 2025
